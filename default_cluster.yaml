---
name: Reg-ER-100-nodes-classification
cpu: No
root_dir: .

train_data: # Train data related parameters
  num_examples_train: 20000
  num_examples_val: 1000
  graph_1:
    generative_model: ErdosRenyi # so far ErdosRenyi, Regular or BarabasiAlbert
    edge_density: 0.5
    n_vertices: 25
    vertex_proba: 1. # Parameter of the binomial distribution of vertices
  graph_2:
    generative_model: ErdosRenyi # so far ErdosRenyi, Regular or BarabasiAlbert
    edge_density: 0.5
    n_vertices: 25
    vertex_proba: 1. # Parameter of the binomial distribution of vertices
  merge_arg:
    generative_model: ErdosRenyi # so far ErdosRenyi, Regular or BarabasiAlbert
    edge_density: 0.2
  path_dataset: dataset # Path where datasets are stored

test_data: # Test data related parameters
  num_examples_test: 1000
  graph_1:
    generative_model: ErdosRenyi # so far ErdosRenyi, Regular or BarabasiAlbert
    edge_density: 0.2
    n_vertices: 25
    vertex_proba: 1. # Parameter of the binomial distribution of vertices
  graph_2:
    generative_model: ErdosRenyi # so far ErdosRenyi, Regular or BarabasiAlbert
    edge_density: 0.2
    n_vertices: 25
    vertex_proba: 1. # Parameter of the binomial distribution of vertices
  merge_arg:
    generative_model: ErdosRenyi # so far ErdosRenyi, Regular or BarabasiAlbert
    edge_density: 0.0
  path_dataset: dataset # Path where datasets are stored

train: # Training parameters
  epoch: 20
  batch_size: 16
  lr: !!float 1e-4
  scheduler_step: 5
  scheduler_decay: 0.9
  print_freq: 100
  # How to reduce the loss over several examples:
  # mean, mean_of_mean
  loss_reduction: mean

arch: # Architecture and model
  arch: Similarity_Model
  # arch: Simple_Node_Embedding
  model_name: Simple_Node_Embedding
  num_blocks: 2
  original_features_num: 2
  in_features: 64
  out_features: 64
  depth_of_mlp: 3
  freeze_mlp: [0, 0, 0] #number of mlp blocks to freeze in each regular block

observers:
  neptune:
    enable: No
    project:
